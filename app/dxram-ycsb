#!/bin/bash

#
# Copyright (C) 2018 Heinrich-Heine-Universitaet Duesseldorf, Institute of Computer Science, Department Operating Systems
#
# This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>
#

# Include guard
if [ "$__CDEPL_APP_DXRAM_YCSB_INCLUDED" ]; then
    return
fi

__CDEPL_APP_DXRAM_YCSB_INCLUDED="1"

readonly __DXRAM_YCSB_BINARY="bin/dxram"

readonly __DXRAM_YCSB_LOG_FILE_LOAD_POSTFIX="_load"
readonly __DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX="_bench"

readonly __DXRAM_YCSB_MAIN_CLASS="de.hhu.bsinfo.dxram.DXRAM"
readonly __DXRAM_YCSB_CLASS_PATH="lib/*"

readonly __DXRAM_YCSB_DEFAULT_S_PORT="22221"
readonly __DXRAM_YCSB_DEFAULT_PS_PORT="22222"
readonly __DXRAM_YCSB_DEFAULT_PB_PORT="22223"

readonly __DXRAM_YCSB_PROCESS_IDENTIFIER="dxramdeployscript"
readonly __DXRAM_YCSB_DONE_COND="\[OVERALL\], RunTime"

readonly __DXRAM_YCSB_REQUIRED_ENVIRONMENT="java/1.8 gcc/6.1"

__DXRAM_YCSB_RESOLVED_DEFAULT_VALUES=""

__DXRAM_YCSB_PATH=""
__DXRAM_YCSB_CONFIG_PATH=""
__DXRAM_YCSB_LOG4J_CONFIG_PATH=""

__DXRAM_YCSB_OUT_PATH=""
__DXRAM_YCSB_OUT_CONF_PATH=""
__DXRAM_YCSB_OUT_LOG_PATH=""

__DXRAM_YCSB_CACHED_NODES_CONFIG=""

__DXRAM_YCSB_ZOOKEEPER_NODE=""
__DXRAM_YCSB_ZOOKEEPER_PORT=""

__DXRAM_YCSB_NODE_TYPE=()
__DXRAM_YCSB_NODE_PORT=()
__DXRAM_YCSB_NODE_NETWORK=()
__DXRAM_YCSB_NODE_MSG_HANDLER=()

__DXRAM_YCSB_NODE_RUN_SUDO=()
__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT=()
__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT=()
__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB=()

__DXRAM_YCSB_TOTAL_STORAGE_NODES=""

__DXRAM_YCSB_LOAD_TARGET_PEER_IDX=()
__DXRAM_YCSB_NODE_THREADS=()

# Specify workload inline
__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE=""
__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT=""
__DXRAM_YCSB_WORKLOAD_READPROPORTION=""
__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION=""
__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION=""
__DXRAM_YCSB_WORKLOAD_FIELDCOUNT=""
__DXRAM_YCSB_WORKLOAD_FIELDLENGTH=""

__DXRAM_YCSB_NODE_INSERTSTART=()

##
# Initialize and setup the DXRAM YCSB environment. This must be called before any
# other function of the dxram-ycsb module.
#
# $1 path Path to folder containing build output of ycsb-dxram with bin, config
#    folder etc
# $2 zookeeper_node Node running the zookeeper server necessary to bootstrap
#    DXRAM
# $3 zookeeper_port Port of the zookeper server running on the specified node
##
cdepl_app_dxram_ycsb_init()
{
	local path=$1
	local zookeeper_node=$2
	local zookeeper_port=$3

	__DXRAM_YCSB_PATH="$(cdepl_cluster_node_cmd 0 "readlink -f $path")"
	__DXRAM_YCSB_CONFIG_PATH="${__DXRAM_YCSB_PATH}/config/dxram.json"
	__DXRAM_YCSB_LOG4J_CONFIG_PATH="${__DXRAM_YCSB_PATH}/config/log4j2.xml"

	__DXRAM_YCSB_OUT_PATH="$(cdepl_run_get_cur_out_path)/dxram_ycsb"
	__DXRAM_YCSB_OUT_CONF_PATH="${__DXRAM_YCSB_OUT_PATH}/conf"
	__DXRAM_YCSB_OUT_LOG_PATH="${__DXRAM_YCSB_OUT_PATH}/log"

	__DXRAM_YCSB_ZOOKEEPER_NODE="$zookeeper_node"
	__DXRAM_YCSB_ZOOKEEPER_PORT="$zookeeper_port"

	# Check if dxram ycsb path is available
	if [ ! "$__DXRAM_YCSB_PATH" ] || [ "$(cdepl_cluster_file_system_cmd "[ -d $__DXRAM_YCSB_PATH ] && echo \"1\"")" != "1" ]; then
		util_log_error_and_exit "[dxram-ycsb]: Path does not exist ($path), resolved path: $__DXRAM_YCSB_PATH"
	fi

	__cdepl_app_dxram_ycsb_check
	__cdepl_app_dxram_ycsb_check_config

	# Output path setup
	cdepl_cluster_file_system_cmd "mkdir -p $__DXRAM_YCSB_OUT_CONF_PATH"
	cdepl_cluster_file_system_cmd "mkdir -p $__DXRAM_YCSB_OUT_LOG_PATH"

	util_log "[dxram-ycsb] Initialized: $__DXRAM_YCSB_PATH"
	util_log "[dxram-ycsb] Output: $__DXRAM_YCSB_OUT_PATH"
}

# in order to declare a node an actual DXRAM node, you have to assign a role
# no default role, node will be ignored and not considered a dxram node

##
# Set the node type for a DXRAM YCSB instance running on a node.
#
# In order to declare a node an actual DXRAM node/instance, you have to assign
# a role. There is no default node role applied, otherwise. The node will be
# ignored and not considered a DXRAM node/instance.
#
# $1 node Node to set the DXRAM YCSB role for
# $2 type DXRAM YCSB node type to set for the specified node:
#    L (loader) or B (benchmark)
##
cdepl_app_dxram_ycsb_node_type()
{
	local node=$1
	local type=$2

	# No default values. If node type not set explicitly, node is not considered to run a DXRAM YCSB instance
	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$type" != "L" ] && [ "$type" != "B" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node type $type for node $node"
	fi

	__DXRAM_YCSB_NODE_TYPE[$node]="$type"
}

##
# Set the port for a node running a DXRAM YCSB instance
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port (ethernet) to set
##
cdepl_app_dxram_ycsb_node_port()
{
	local node=$1
	local port=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$port" -gt "65536" ] || [ "$port" -lt "0" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid port $port for node $node"
	fi

	__DXRAM_YCSB_NODE_PORT[$node]="$port"
}

##
# Set the network type of DXRAM YCSB instance on the target node
#
# $1 node Node of the DXRAM YCSB instance
# $2 network Network type to set (eth, ib)
##
cdepl_app_dxram_ycsb_node_network()
{
	local node=$1
	local network=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$network" != "eth" ] && [ "$network" != "ib" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid network type $network for node $node"
	fi

	__DXRAM_YCSB_NODE_NETWORK[$node]="$network"
}

##
# Set the number of message handlers for the network subsystem to use for the
# DXRAM YCSB instance running on the target node
#
# $1 node Node of the DXRAM YCSB instance
# $2 msg_handler Number of message handlers to use on the specified node
##
cdepl_app_dxram_ycsb_node_message_handler()
{
	local node=$1
	local msg_handler=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_MSG_HANDLER[$node]="$msg_handler"
}

##
# Run the DXRAM YCSB instance with sudo on the target node (e.g. might be necessary
# if using InfiniBand networking)
#
# $1 node Node of the DXRAM YCSB instance
##
cdepl_app_dxram_ycsb_run_as_sudo()
{
	local node=$1

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	if [ "$(cdepl_cluster_allows_sudo)" ]; then
		__DXRAM_YCSB_NODE_RUN_SUDO[$node]="1"
	else
		util_log_warn "[$node][dxram-ycsb] Cluster type does not allow running commands as sudo, ignored"
	fi
}

##
# Run the DXRAM YCSB instance with parameters to enable remote debugging. Once
# enabled, a string with information how to attach the debugger will be printed
# on deployment
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port to assign to the debugger to use
##
cdepl_app_dxram_ycsb_remote_debug()
{
	local node=$1
	local port=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]="$port"
}

##
# Run the DXRAM YCSB instance with parameters to enable profiling with the Yourkit
# profiler. A string with information how to attach the debugger will be printed
# on deployment
#
# $1 node Node of the DXRAM YCSB instance
# $2 port Port for the remote profiler
# $3 agent_lib Path on the target node with the libyjpagent.so lib
##
cdepl_app_dxram_ycsb_remote_profile_yjp()
{
	local node=$1
	local port=$2
	local agent_lib=$3

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	# Check if the agent lib is available
	if [ "$(cdepl_cluster_node_cmd $node "[ -f $agent_lib ] && echo \"1\"")" != "1" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Could not find libyjpagent.so in $agent_lib"
	fi

	__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]="$port"
	__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB[$node]="$agent_lib"
}

##
# Set the total number of storage nodes for the YCSB benchmark
#
# #1 total_nodes Total number of storages nodes
##
cdepl_app_dxram_ycsb_total_storage_nodes()
{
	local total_nodes=$1

	__DXRAM_YCSB_TOTAL_STORAGE_NODES="$total_nodes"
}

##
# Set the target node to load the data to
#
# $1 node Target benchmark node
# $2 target_peer_node_idx Target peer (storage) peer idx node to load. Idx range is 0 to <num storage peers>.
##
cdepl_app_dxram_ycsb_load_target_peer_idx()
{
	local node=$1
	local target_peer_node_idx=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_LOAD_TARGET_PEER_IDX[$node]="$target_peer_node_idx"
}


##
# Set the number of ycsb threads to run on a benchmark node
#
# $1 node Target benchmark node
# $2 threads Number of threads to start on the target benchmark node
##
cdepl_app_dxram_ycsb_threads()
{
	local node=$1
	local threads=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_THREADS[$node]="$threads"
}

##
# Specify an inline workload instead of using a workload config making the
# deployment script more self containing
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
# $3 readportion Distribution of reads
# $4 updateportion Distribution of updates
# $5 requestdistribution Distribution of requests (zipfian, uniform)
# $6 fieldcount Number of fields per object
# $7 fieldlength Length of a single field
##
cdepl_app_dxram_ycsb_workload()
{
	local recordcount=$1
	local operationcount=$2
	local readportion=$3
	local updateportion=$4
	local requestdistribution=$5
	local fieldcount=$6
	local fieldlength=$7

	__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE="$recordcount"
	__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT="$operationcount"
	__DXRAM_YCSB_WORKLOAD_READPROPORTION="$readportion"
	__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION="$updateportion"
	__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION="$requestdistribution"
	__DXRAM_YCSB_WORKLOAD_FIELDCOUNT="$fieldcount"
	__DXRAM_YCSB_WORKLOAD_FIELDLENGTH="$fieldlength"
}

##
# Set the insert start offset when creating/inserting objects during loading
#
# $1 node Target storage node
# $2 insertstart Insert start offset for chunk IDs
##
cdepl_app_dxram_ycsb_insertstart()
{
	local node=$1
	local insertstart=$2

	if [ "$node" -ge "$(cdepl_cluster_get_alloc_node_count)" ]; then
		util_log_error_and_exit "[$node][dxram-ycsb] Invalid node id $node > $(cdepl_cluster_get_alloc_node_count)"
	fi

	__DXRAM_YCSB_NODE_INSERTSTART[$node]="$insertstart"
}

##
# Wrapper to set workload a
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_a()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.5" "0.5" "zipfian" "10" "100"
}

##
# Wrapper to set workload b
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_b()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.95" "0.05" "zipfian" "10" "100"
}

##
# Wrapper to set workload g
#
# $1 recordcount Number of records to create per node
# $2 operationcount Number of operations to execute by each benchmark node
##
cdepl_app_dxram_ycsb_workload_g()
{
	local recordcount=$1
	local operationcount=$2

	cdepl_app_dxram_ycsb_workload $recordcount $operationcount "0.5" "0.5" "zipfian" "1" "64"
}

##
# Start a DXRAM YCSB instance on the target node.
#
# $1 node_range_start Node id to start instance on (or range start)
# $2 node_range_end (optional) If specified, all nodes from the range start to
#    end are started
##
cdepl_app_ycsb_dxram_start_node()
{
	local node_range_start=$1
	local node_range_end=$2

	# Resolve once before first node is started
	if [ ! "$__DXRAM_YCSB_RESOLVED_DEFAULT_VALUES" ]; then
		__DXRAM_YCSB_RESOLVED_DEFAULT_VALUES="1"
		__cdepl_app_dxram_ycsb_resolve_default_config_values
	fi

	if [ "$node_range_end" ]; then
		local counter=0
		local pids=""

		for node in $(seq $node_range_start $node_range_end); do
			__cdepl_app_ycsb_dxram_start_node $node &
			pids="$pids $!"
		
			counter=$((counter + 1))

			# Parallel deploy in batches of 10 which is the default limit
			# for parallel connections on ssh servers, stay slightly below 
			# this limit (sometimes, 10 causes errors on multiplexing)
			if [ "$counter" -ge "8" ]; then
				wait $pids
				pids=""
				counter=0
			fi
		done

		wait $pids
	else
		__cdepl_app_ycsb_dxram_start_node $node_range_start
	fi
}

##
# Check for a YCSB loader instance if it finished loading
#
# $1 node Node id of a strange node to check
# $2 hide_progress (optional) Set to 1 to hide output of the loading progress
##
cdepl_app_dxram_ycsb_loader_finished_loading()
{
	local node=$1
	local hide_progress=$2

	local type="${__DXRAM_YCSB_NODE_TYPE[$node]}"
	local logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_LOAD_POSTFIX}

	if [ "$type" != "L" ]; then
		util_log_error "[$node][dxram-ycsb][$type] Invalid node type $type to wait for loader finish"
		return
	fi

	util_log "[$node][dxram-ycsb][$type] Waiting for loading to finish: $__DXRAM_YCSB_DONE_COND"

	local first_progress=1

	while true; do
		if [ ! "$hide_progress" ]; then
			local progress=$(cdepl_cluster_node_cmd $node "cat $logfile | grep 'current ops' | tail -n 1")

			if [ ! "$progress" ]; then
				echo -n "."
			else
				if [ "$first_progress" = "1" ]; then
					first_progress=0
					echo ""
				fi

				echo "[$node] ${progress}"
			fi
		else
			echo -n "."
		fi

		local success=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '$__DXRAM_YCSB_DONE_COND'")
		# Abort execution after an exception was thrown (every exception but NetworkResponseCancelledException)
		local fail_error=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i 'exception' | grep -v 'NetworkResponseCancelledException' | grep -v 'fpu_exception'")
		# "A fatal error" -> JVM segfaults
		local fail_error2=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i -e '\[ERROR\]' -e '\# A fatal error'")

		if [ "$fail_error" ] || [ "$fail_error2" ]; then
			echo ""
			err=""
			
			if [ "$fail_error" ]; then
				err="$fail_error"
			else
				err="$fail_error2"
			fi

			util_log_error "[$node][dxram-ycsb][$type] Failed, error or exception:\n${err}\nSee log file $logfile"
			return
		fi

		if [ "$success" ]; then
			echo ""
			util_log "[$node][dxram-ycsb][$type] Storage loading complete"
			break;
		fi

		sleep 1.0
	done

	return 0
}

##
# Check for a YCSB benchmark instance if it running the benchmark
#
# $1 node Node id of a benchmark node to check
# $2 hide_progress (optional) Set to 1 to hide output of the benchmark progress
##
cdepl_app_dxram_ycsb_benchmark_wait_finished()
{
	local node=$1
	local hide_progress=$2

	local type="${__DXRAM_YCSB_NODE_TYPE[$node]}"
	local logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX}

	if [ "$type" != "B" ]; then
		util_log_error "[$node][dxram-ycsb][$type] Invalid node type $type to wait for benchmark to finish"
		return
	fi

	util_log "[$node][dxram-ycsb][$type] Waiting for benchmark to finish: $__DXRAM_YCSB_DONE_COND"

	local first_progress=1

	while true; do
		if [ ! "$hide_progress" ]; then
			local progress=$(cdepl_cluster_node_cmd $node "cat $logfile | grep 'current ops' | tail -n 1")

			if [ ! "$progress" ]; then
				echo -n "."
			else
				if [ "$first_progress" = "1" ]; then
					first_progress=0
					echo ""
				fi

				echo "[$node] ${progress}"
			fi
		else
			echo -n "."
		fi

		local success=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep '$__DXRAM_YCSB_DONE_COND'")
		# Abort execution after an exception was thrown (every exception but NetworkResponseCancelledException)
		local fail_error=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i 'exception' | grep -v 'NetworkResponseCancelledException' | grep -v 'fpu_exception'")
		# "A fatal error" -> JVM segfaults
		local fail_error2=$(cdepl_cluster_node_cmd $node "cat $logfile 2> /dev/null | sed 's,\x1B\[[0-9;]*[a-zA-Z],,g' | grep -i -e '\[ERROR\]' -e '\# A fatal error'")

		if [ "$fail_error" ] || [ "$fail_error2" ]; then
			echo ""
			err=""
			
			if [ "$fail_error" ]; then
				err="$fail_error"
			else
				err="$fail_error2"
			fi

			util_log_error "[$node][dxram-ycsb][$type] Failed, error or exception:\n${err}\nSee log file $logfile"
			return
		fi

		if [ "$success" ]; then
			echo ""
			util_log "[$node][dxram-ycsb][$type] Benchmark completed"
			break;
		fi

		sleep 1.0
	done

	return 0
}

##
# Cleanup any still running or remaining/crashed instances on the target node
#
# $1 Target node id (or start node id of range if second parameter provided)
# $2 Optional: Node id range end (including) and first parameter is interpreted
#    as range start (including)
##
cdepl_app_dxram_ycsb_node_cleanup()
{
	local node_range_start=$1
	local node_range_end=$2

	if [ "$node_range_end" ]; then
		local counter=0
		local pids=""

		for node in $(seq $node_range_start $node_range_end); do
			__cdepl_app_dxram_ycsb_cleanup $node &
			pids="$pids $!"

			counter=$((counter + 1))

			# Parallel deploy in batches of 10 which is the default limit
			# for parallel connections on ssh servers, stay slightly below 
			# this limit (sometimes, 10 causes errors on multiplexing)
			if [ "$counter" -ge "8" ]; then
				wait $pids
				sleep 1
				pids=""
				counter=0
			fi
		done

		wait $pids
	else
		__cdepl_app_dxram_ycsb_cleanup $node_range_start
	fi
}

#################################################

__cdepl_app_dxram_ycsb_check()
{
	if [ "$(cdepl_cluster_node_cmd 0 "[ -f ${__DXRAM_YCSB_PATH}/bin/ycsb ] && echo 1")" != "1" ]; then
		util_log_error "[0][dxram-ycsb] Could not find bin/ycsb in $__DXRAM_YCSB_PATH"
	fi
}

__cdepl_app_dxram_ycsb_check_config()
{
	# Check if config file is available and create default config
	if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
		util_log "[0][dxram-ycsb] No config file available, creating default config: $__DXRAM_YCSB_CONFIG_PATH"

		# Don't run this on the login node (might not have java installed)
		# Use the first actual cluster node instead
		# sync: Ensure everything's written to disk and visible for other nodes
		cdepl_cluster_node_cmd 0 "cd $__DXRAM_YCSB_PATH && DXRAM_OPTS='-Ddxram.config=$__DXRAM_CONFIG_PATH' ./$__DXRAM_YCSB_BINARY > /dev/null 2>&1" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"

		# Sanity check
		if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
			util_log_error "[0][dxram-ycsb] Creating config file $__DXRAM_YCSB_CONFIG_PATH failed"
		fi
	else
		local config_content="$(cdepl_cluster_node_cmd 0 "cat "$__DXRAM_YCSB_CONFIG_PATH"")"
		# Check if corrupted configuration file
		local component_header=`echo $config_content | grep "m_componentConfigs"`
		local service_header=`echo $config_content | grep "m_serviceConfigs"`
		if [ "$component_header" = "" ] && [ "$service_header" = "" ] ; then
			util_log "[0][dxram-ycsb] Configuration file $__DXRAM_YCSB_CONFIG_PATH corrupted, deleting and creating default"

			# Configuration file seems to be corrupted -> start dxram once to create new configuration
			cdepl_cluster_node_cmd 0 "rm $__DXRAM_YCSB_CONFIG_PATH && cd $__DXRAM_YCSB_PATH && DXRAM_OPTS='-Ddxram.config=$__DXRAM_CONFIG_PATH' ./$__DXRAM_YCSB_BINARY > /dev/null 2>&1" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"

			# Sanity check
			if [ "$(cdepl_cluster_node_cmd 0 "[ -f $__DXRAM_YCSB_CONFIG_PATH ] && echo \"1\"")" != "1" ]; then
				util_log_error "[0][dxram-ycsb] Creating config file $__DXRAM_YCSB_CONFIG_PATH failed"
			fi
		fi
	fi
}

__cdepl_app_dxram_ycsb_resolve_default_config_values()
{
	local node_count="$(cdepl_cluster_get_alloc_node_count)"

	for i in `seq 0 $((node_count - 1))`; do
		# Only for explicitly set node types = DXRAM instance
		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "S" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_S_PORT"
		fi

		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PS" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_PS_PORT"
		fi

		if [ "${__DXRAM_YCSB_NODE_TYPE[$i]}" = "PB" ] && [ "${__DXRAM_YCSB_NODE_PORT[$i]}" = "" ]; then
			__DXRAM_YCSB_NODE_PORT[$i]="$__DXRAM_YCSB_DEFAULT_PB_PORT"
		fi
	done
}

__cdepl_app_dxram_ycsb_create_node_base_config()
{
	local node=$1
	local node_config_path="${__DXRAM_YCSB_OUT_CONF_PATH}/node_${node}.conf"

	cdepl_cluster_file_system_cmd "cp $__DXRAM_YCSB_CONFIG_PATH $node_config_path"
}

__cdepl_app_ycsb_dxram_start_node()
{
	local node=$1

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "" ]; then
		util_log_error "[$node][dxram-ycsb] No node type set, cannot start instance"
		return
	fi

	local logfile=""

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "L" ]; then
		logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_LOAD_POSTFIX}
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "B" ]; then
		logfile=${__DXRAM_YCSB_OUT_LOG_PATH}/node${node}${__DXRAM_YCSB_LOG_FILE_BENCH_POSTFIX}
	else
		util_log_error "[$node][dxram-ycsb] Invalid node type ${__DXRAM_YCSB_NODE_TYPE[$node]} cannot start instance"
		return
	fi

	
	__cdepl_app_dxram_ycsb_create_node_base_config $node

	if [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "L" ]; then
		__cdepl_app_dxram_ycsb_start_peer $node "load" $logfile
	elif [ "${__DXRAM_YCSB_NODE_TYPE[$node]}" = "B" ]; then
		__cdepl_app_dxram_ycsb_start_peer $node "run" $logfile
	fi
}

__cdepl_app_dxram_ycsb_start_peer()
{
	local node=$1
	local ycsb_type=$2
	local logfile=$3

	local node_config_path="${__DXRAM_YCSB_OUT_CONF_PATH}/node_${node}.conf"

	util_log "[$node][dxram-ycsb][$ycsb_type] Starting $ycsb_type peer, logfile: $logfile config: $node_config_path"

	local ip="$(cdepl_cluster_resolve_hostname_to_ip "$(cdepl_cluster_node_resolve_node_to_hostname $node)")"

	if [ ! "$ip" ]; then
		util_log_error "[$node][dxram-ycsb][$ycsb_type] Could not resolve hostname '$(cdepl_cluster_node_resolve_node_to_hostname $node)' to ip"
		return
	fi

	local zookeeper_ip="$(cdepl_cluster_resolve_node_to_ip $__DXRAM_YCSB_ZOOKEEPER_NODE)"

	if [ zookeeper_ip = "" ]; then
		util_log_error "[$node][dxram-ycsb][$ycsb_type] Could not resolve zookeeper ip for node $__DXRAM_YCSB_ZOOKEEPER_NODE"
		return
	fi

	local vm_opts=""
	local ycsb_params=""

	# Required to fix JNI crashing with libIbdxnet (see JNINotes.md in ibnet repository)
	vm_opts="-XX:+UseMembar"

	vm_opts="$vm_opts -Dlog4j.configurationFile=$__DXRAM_YCSB_LOG4J_CONFIG_PATH"
	vm_opts="$vm_opts -Ddxram.config=$node_config_path"
	vm_opts="$vm_opts -Ddxram.m_engineConfig.m_address.m_ip=$ip"
	vm_opts="$vm_opts -Ddxram.m_engineConfig.m_address.m_port=${__DXRAM_YCSB_NODE_PORT[$node]}"
	vm_opts="$vm_opts -Ddxram.m_engineConfig.m_role=Peer"

	# ZooKeeper connection settings
	local zookeeper_ip="$(cdepl_cluster_resolve_node_to_ip "$__DXRAM_YCSB_ZOOKEEPER_NODE")"
	vm_opts="$vm_opts -Ddxram.m_componentConfigs[ZookeeperBootComponent].m_connection.m_ip=${zookeeper_ip}"
	vm_opts="$vm_opts -Ddxram.m_componentConfigs[ZookeeperBootComponent].m_connection.m_port=${__DXRAM_YCSB_ZOOKEEPER_PORT}"

	# Optional dxram node specific settings

	if [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "eth" ]; then
		vm_opts="$vm_opts -Ddxram.m_componentConfigs[NetworkComponent].m_coreConfig.m_device=ethernet"
	elif [ "${__DXRAM_YCSB_NODE_NETWORK[$node]}" = "ib" ]; then
		vm_opts="$vm_opts -Ddxram.m_componentConfigs[NetworkComponent].m_coreConfig.m_device=infiniband"
	fi

	if [ "${__DXRAM_YCSB_NODE_MSG_HANDLER[$node]}" ]; then
		vm_opts="$vm_opts -Ddxram.m_componentConfigs[NetworkComponent].m_coreConfig.m_numMessageHandlerThreads=${__DXRAM_YCSB_NODE_MSG_HANDLER[$node]}"
	fi

	# Disable key value storage
	vm_opts="$vm_opts -Ddxram.m_componentConfigs[ChunkComponent].m_chunkStorageEnabled=false"

	# Development and debugging

	local root=""
	if [ "${__DXRAM_YCSB_NODE_RUN_SUDO[$node]}" = "1" ]; then
		util_log "[$node][dxram-ycsb][$ycsb_type] Running with sudo"
		root="sudo -E -P"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][$ycsb_type] Enabled remote debugging on port ${DXRAM_NODE_REMOTE_DEBUG_PORT[$node]}"
		util_log "[$node][dxram-ycsb][$ycsb_type] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}' and connect your debugger to localhost, port ${__DXRAM_YCSB_NODE_REMOTE_DEBUG_PORT[$node]}"
	fi

	if [ "${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}" != "" ]; then
		vm_opts="$vm_opts -agentpath:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_AGENT_LIB[$node]}=port=${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}"

		util_log "[$node][dxram-ydxb][$ycsb_type] On your local machine: establish a tunnel using 'ssh <target_hostname> -L ${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}:<target_hostname>:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}' and connect with yourkit using 'Connect to remote application' with the arguments 'localhost:${__DXRAM_YCSB_NODE_REMOTE_PROFILE_YJP_PORT[$node]}'"
	fi

	vm_opts="$vm_opts -D${__DXRAM_YCSB_PROCESS_IDENTIFIER}"

	# YCSB settings

	ycsb_params="$ycsb_params -p status.interval=1"

	if [ ! "$__DXRAM_YCSB_TOTAL_STORAGE_NODES" ]; then
		util_log_error "[$node][dxram-ycsb][$ycsb_type] Cannot run DXRAM client without total storage nodes parameter specified"
		return
	fi

	ycsb_params="$ycsb_params -p dxram.stores=$__DXRAM_YCSB_TOTAL_STORAGE_NODES"

	if [ ! "${__DXRAM_YCSB_NODE_THREADS[$node]}" ] || [ "$ycsb_type" = "load" ]; then
		# Auto default to single thread
		# And limit to single threaded on storage load nodes
		__DXRAM_YCSB_NODE_THREADS[$node]="1"
	fi

	if [ ! "${__DXRAM_YCSB_NODE_INSERTSTART[$node]}" ] && [ "$ycsb_type" = "load" ]; then
		util_log_error "[$node][dxram-ycsb][$ycsb_type] Missing value for insertstart parameter for storage"
		return
	fi

	if [ "${__DXRAM_YCSB_NODE_INSERTSTART[$node]}" ]; then
		ycsb_params="$ycsb_params -p insertstart=${__DXRAM_YCSB_NODE_INSERTSTART[$node]}"
	fi

	# Force ordered because hashing is not supported by dxram
	ycsb_params="$ycsb_params -p insertorder=ordered"
	ycsb_params="$ycsb_params -p readallfields=true"
	ycsb_params="$ycsb_params -p scanproportion=0.0"

	if [ "$__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE" ]; then
		ycsb_params="$ycsb_params -p dxram.recordsPerStoreNode=$__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE"

		# For the storage nodes: how many records it has to load
		# For the benchmark node: total number of records in the whole DB
		if [ "$ycsb_type" = "load" ]; then
			ycsb_params="$ycsb_params -p dxram.load.targetNodeIdx=${__DXRAM_YCSB_LOAD_TARGET_PEER_IDX[$node]}"
			ycsb_params="$ycsb_params -p recordcount=$__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE"
		else
			ycsb_params="$ycsb_params -p recordcount=$((__DXRAM_YCSB_WORKLOAD_RECORDCOUNT_PER_NODE * __DXRAM_YCSB_TOTAL_STORAGE_NODES))"
		fi
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT" ]; then
		ycsb_params="$ycsb_params -p operationcount=$__DXRAM_YCSB_WORKLOAD_OPERATIONCOUNT"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_READPROPORTION" ]; then
		ycsb_params="$ycsb_params -p readproportion=$__DXRAM_YCSB_WORKLOAD_READPROPORTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION" ]; then
		ycsb_params="$ycsb_params -p updateproportion=$__DXRAM_YCSB_WORKLOAD_UPDATEPROPORTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION" ]; then
		ycsb_params="$ycsb_params -p requestdistribution=$__DXRAM_YCSB_WORKLOAD_REQUESTDISTRIBUTION"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_FIELDCOUNT" ]; then
		ycsb_params="$ycsb_params -p fieldcount=$__DXRAM_YCSB_WORKLOAD_FIELDCOUNT"
	fi

	if [ "$__DXRAM_YCSB_WORKLOAD_FIELDLENGTH" ]; then
		ycsb_params="$ycsb_params -p fieldlength=$__DXRAM_YCSB_WORKLOAD_FIELDLENGTH"
	fi

	# Assuming the ycsb and dxram folders are merged

	# Use workloada as default if no further parameters are overwriting the default workload
	# JVM options must be specified using the JAVA_OPTS env var

	# Don't use && instead of ;
	# This will hang if ssh with controlmaster and nohup is used
	cdepl_cluster_node_cmd $node "cd $__DXRAM_YCSB_PATH ; $root nohup ./bin/ycsb $ycsb_type dxram -jvm-args '$vm_opts' -threads ${__DXRAM_YCSB_NODE_THREADS[$node]} -s -P workloads/workloada $ycsb_params > $logfile 2>&1 &" "$__DXRAM_YCSB_REQUIRED_ENVIRONMENT"
}

__cdepl_app_dxram_ycsb_get_instance_running_pid()
{
	local node=$1
	local port=$2

	if [ "$port" ]; then
		port=".*-Ddxram.m_engineConfig.m_address.m_port=${port}"
	fi

	# Consider port for multiple instances on a single machine (e.g. localhost)
	echo "$(cdepl_cluster_node_cmd $node "pgrep -f '^java${port}.*-D${__DXRAM_YCSB_PROCESS_IDENTIFIER}'")"
}

__cdepl_app_dxram_ycsb_cleanup()
{
	local node=$1

	util_log "[$node][dxram-ycsb] Cleanup..."

	local pid=$(__cdepl_app_dxram_ycsb_get_instance_running_pid $node)

	if [ "$pid" ]; then
		# If we or someone else left some garbage processes on the node multiple
		# pids are returned
		for i in $pid; do
			local kill_out=$(cdepl_cluster_node_cmd $node "kill -9 $i 2>&1")

			if [ "$?" = "0" ] && [ ! "$kill_out" ]; then
				util_log "[$node][dxram-ycsb] Killed (pid: $i)"
			elif [ "$kill_out" ]; then
				# Probably operation not permitted, try root
				cdepl_cluster_node_cmd $node "sudo -P kill -9 $i > /dev/null 2>&1"

				if [ "$?" = "0" ]; then
					util_log "[$node][dxram-ycsb] Killed (root) (pid: $i)"
				elif [ "$?" != "1" ]; then
					util_log_warn "[$node][dxram-ycsb] Killing (root) $i failed, DXRAM YCSB instance(s) might stay alive"
				fi
			elif [ "$?" != "1" ]; then
				util_log_warn "[$node][dxram-ycsb] Killing $i failed, DXRAM YCSB instance(s) might stay alive"
			fi
		done
	fi
}
